panel.background = element_blank(), axis.line = element_line(colour = "black")) +
annotate('point', x=best_params[1], y=best_params[2], color='orange', size=2) +
xlab('Shape')  +
ylab('Scale') +
scale_y_log10()
#ggtitle(likelihood_surface_title)
return(fig)
}
find_dfe_mle = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('shape', 'scale', 'likelihood')
unique_shape = unique(species_surface$shape)
unique_scale = unique(species_surface$scale)
Z = matrix(data=NA, nrow=length(unique_shape), ncol=length(unique_scale))
count = 1
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
best_params = c(species_surface$shape[1], species_surface$scale[1])
print(best_params)
MLE = max(species_surface$likelihood)
print(MLE)
}
cross_species_dfe_comparison = function(input_A, input_B) {
species_surface_A = read.csv(input_A, header=TRUE)
names(species_surface_A) = c('shape', 'scale', 'likelihood')
unique_shape_A = unique(species_surface_A$shape)
unique_scale_A = unique(species_surface_A$scale)
Z_A = matrix(data=NA, nrow=length(unique_shape_A), ncol=length(unique_scale_A))
count = 1
for (i in 1:length(unique_shape_A)) {
for (j in 1:length(unique_scale_A)) {
Z_A[i, j] = species_surface_A$likelihood[count]
if (species_surface_A$shape[count] != unique_shape_A[i]) {
print('break')
} else if (species_surface_A$scale[count] != unique_scale_A[j]) {
print('break')
}
count = count + 1
}
}
temp_surface_A = species_surface_A[order(species_surface_A$likelihood, decreasing=TRUE), ]
best_params_A = c(temp_surface_A$shape[1], temp_surface_A$scale[1])
ML_A = temp_surface_A$likelihood[1]
species_surface_B = read.csv(input_B, header=TRUE)
names(species_surface_B) = c('shape', 'scale', 'likelihood')
unique_shape_B = unique(species_surface_B$shape)
unique_scale_B = unique(species_surface_B$scale)
Z_B = matrix(data=NA, nrow=length(unique_shape_B), ncol=length(unique_scale_B))
count = 1
for (i in 1:length(unique_shape_B)) {
for (j in 1:length(unique_scale_B)) {
Z_B[i, j] = species_surface_B$likelihood[count]
if (species_surface_B$shape[count] != unique_shape_B[i]) {
print('break')
} else if (species_surface_B$scale[count] != unique_scale_B[j]) {
print('break')
}
count = count + 1
}
}
temp_surface_B = species_surface_B[order(species_surface_B$likelihood, decreasing=TRUE), ]
best_params_B = c(temp_surface_B$shape[1], temp_surface_B$scale[1])
ML_B = temp_surface_B$likelihood[1]
combined_likelihood = species_surface_A$likelihood + species_surface_B$likelihood
comparison_surface = data.frame(species_surface_A$shape, species_surface_A$scale, combined_likelihood)
temp_comparison_surface = comparison_surface[order(comparison_surface$combined_likelihood, decreasing=TRUE), ]
best_params_comparison = c(temp_comparison_surface$species_surface_A.shape[1], temp_comparison_surface$species_surface_A.scale[1])
ML_comparison = temp_comparison_surface$combined_likelihood[1]
independent_sum = ML_A + ML_B
return(ML_comparison - independent_sum)
}
compare_core_accessory_sfs = function(all, core, accessory) {
x_axis = 1:length(all)
input_df = data.frame(proportional_sfs(all),
proportional_sfs(core),
proportional_sfs(accessory),
x_axis)
names(input_df) = c('All genes',
'Core genes',
'Accessory genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
compare_core_accessory_sfs_count = function(all, core, accessory) {
x_axis = 1:length(all)
input_df = data.frame(all,
core,
accessory,
x_axis)
names(input_df) = c('All genes',
'Core genes',
'Accessory genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
compare_core_accessory_sfs_syn_ns = function(core_syn, core_nonsyn, accessory_syn, accessory_nonsyn) {
x_axis = 1:length(core_syn)
input_df = data.frame(proportional_sfs(core_syn),
proportional_sfs(core_nonsyn),
proportional_sfs(accessory_syn),
proportional_sfs(accessory_nonsyn),
x_axis)
names(input_df) = c('Core genes (Syn)',
'Core genes (Nonsyn)',
'Accessory genes (Syn)',
'Accessory genes (Nonsyn)',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1"))
return(p_input_comparison)
}
compare_core_sfs = function(all, core) {
x_axis = 1:length(all)
input_df = data.frame(proportional_sfs(all),
proportional_sfs(core),
x_axis)
names(input_df) = c('All genes',
'Core genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
extract_array_length <- function(input_string) {
array_string <- str_extract(input_string, "\\[(.*?)\\]")
num_elements <- length(strsplit(array_string, "[ ,]")[[1]])
return(num_elements)
}
AIC_from_demography = function(input_file) {
## Reads input SFS from output *demography.txt
if(grepl("one_epoch", input_file)) {
k=2
} else if(grepl("two_epoch", input_file)) {
k=4
} else {
k=8
}
this_file = file(input_file)
on.exit(close(this_file))
ll_string = readLines(this_file)[2]
loglik <- as.numeric(str_extract(ll_string, "-?\\d+\\.\\d+"))
return(k - 2*loglik)
}
return_nu_high = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
highest_nu <- max(species_surface$nu)
return(highest_nu)
}
return_nu_low = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
lowest_nu <- min(species_surface$nu)
return(lowest_nu)
}
return_nu_mle = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
return(species_surface$nu[1])
}
return_time_high = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
highest_tau <- max(species_surface$tau)
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * highest_tau * theta / (4 * mu_low * allele_sum)
years = 2 * highest_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
return_time_low = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
lowest_tau <- min(species_surface$tau)
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * lowest_tau * theta / (4 * mu_low * allele_sum)
years = 2 * lowest_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
return_time_mle = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
mle_tau = species_surface$tau[i]
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * mle_tau * theta / (4 * mu_low * allele_sum)
years = 2 * mle_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
read_demography_info <- function(filepath) {
# Read the content of the file
file_content <- readLines(filepath)
# Extract the relevant lines
nu <- as.numeric(regmatches(file_content[1], regexpr("\\d+\\.\\d+", file_content[1])))
low_years <- as.numeric(regmatches(file_content[length(file_content)-3], regexpr("\\d+\\.\\d+", file_content[length(file_content)-3])))
low_ancestral_size <- as.numeric(regmatches(file_content[length(file_content)-1], regexpr("\\d+\\.\\d+", file_content[length(file_content)-1])))
# Create a vector with the extracted information
result_vector <- c(nu, low_years, low_ancestral_size)
return(result_vector)
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pchisq(274.376417233, 1, lower.tail=FALSE)
update.packages()
data = c(0.590, 0.08, 0, 0)
p_bar = mean(data)
q_bar = 1-p_bar
var_p = var(data)
var_p
var_p / p_bar / q_bar
q_bar
p_bar
var_p
var(data)
variance(data)
?var
var_p = 0.06056875
var_p / (p_bar * q_bar)
data_2 = c(0.323, 0.384, 0.229, 0.087)
p_bar_2 = mean(data_2)
q_bar_2 = 1 - p_bar_2
var_p_2 = 0.012540688
var_p_2 / p_bar_2 / q_bar_2
p_bar_2
q_bar_2
var_p_2
N <- 10000              # Population size
s <- 0.2                # Selection coefficient
h <- 0.5                # Dominance coefficient
p <- 1 / (2 * N)        # Initial frequency of light allele (1 heterozygous immigrant)
max_gen <- 500          # Max generations to simulate
# Storage for tracking allele frequency
p_vec <- numeric(max_gen)
p_vec[1] <- p
# Fitness values
w_LL <- 1 + s
w_LD <- 1 + h * s
w_DD <- 1
# Iterate over generations
for (gen in 2:max_gen) {
# Genotype frequencies (HWE assumption)
p <- p_vec[gen - 1]
q <- 1 - p
f_LL <- p^2
f_LD <- 2 * p * q
f_DD <- q^2
# Mean fitness of population
w_bar <- f_LL * w_LL + f_LD * w_LD + f_DD * w_DD
# New allele frequency after selection
p_next <- (f_LL * w_LL + 0.5 * f_LD * w_LD) / w_bar
p_vec[gen] <- p_next
# Stop early if allele frequency reaches 0.9
if (p_next >= 0.9) {
cat("Reached p = 0.9 at generation", gen, "\n")
p_vec <- p_vec[1:gen]
break
}
}
# Plot allele frequency over generations
plot(p_vec, type = "l", lwd = 2, col = "blue",
xlab = "Generation", ylab = "Frequency of light allele (p)",
main = "Allele Frequency Over Time under Selection")
abline(h = 0.9, col = "red", lty = 2)
?abline
abline(v = 131, col = 'green', lty=1)
# Plot allele frequency over generations
plot(p_vec, type = "l", lwd = 2, col = "blue",
xlab = "Generation", ylab = "Frequency of light allele (p)",
main = "Allele Frequency Over Time under Selection",
xlim = c(0, 140))
abline(h = 0.9, col = "red", lty = 2)
abline(v = 131, col = 'green', lty=1)
# figure_3.R
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source('useful_functions.R')
sample_size = seq(from=10, to=800, by=10)
mean_list = c()
sd_list = c()
growth_proportion = c()
bottleneck_proportion = c()
ancestral_proportion = c()
dadi_nu_shape = c()
dadi_time = c()
msprime_time = c()
msprime_nu_shape = c()
# Iterate through sample size and replicate
for (i in sample_size) {
this_sample_size_distribution = c() # Initialize
dadi_demography = paste0(
"../Analysis/dadi_3EpB_", i, '/two_epoch_demography.txt')
dadi_nu = nu_from_demography(dadi_demography)
dadi_time = c(dadi_time, time_from_demography(dadi_demography))
msprime_demography = paste0(
"../Analysis/msprime_3EpB_", i, '/two_epoch_demography.txt')
msprime_nu = nu_from_demography(msprime_demography)
msprime_time = c(msprime_time, time_from_demography(msprime_demography))
if (is.na(dadi_nu)) {
dadi_nu_shape = c(dadi_nu_shape, NA)
} else if (dadi_nu > 1) {
dadi_nu_shape = c(dadi_nu_shape, 'dadi_expand')
} else {
dadi_nu_shape = c(dadi_nu_shape, 'dadi_contract')
}
if (is.na(msprime_nu)) {
msprime_nu_shape = c(msprime_nu_shape, NA)
} else if (msprime_nu > 1) {
msprime_nu_shape = c(msprime_nu_shape, 'msprime_expand')
} else {
msprime_nu_shape = c(msprime_nu_shape, 'msprime_contract')
}
for (j in seq(from=1, to=20, by=1)) {
this_replicate_distribution = paste0(
"../Simulations/simple_simulations/ThreeEpochBottleneck_",
i, '_coal_dist_',
j, '.csv')
# Read in the appropriate file
this_csv = read.csv(this_replicate_distribution, header=TRUE)
this_sample_size_distribution = c(this_sample_size_distribution, this_csv$generations)
}
# Take the mean of coalescent times for this sample size's distribution
mean_list = c(mean_list, mean(this_sample_size_distribution))
# Similarly, take standard deviation
sd_list = c(sd_list, sd(this_sample_size_distribution))
# Lastly find the proportion of coalescent events in each epoch
growth_proportion = c(growth_proportion,
mean(this_sample_size_distribution < 200))
bottleneck_proportion = c(bottleneck_proportion,
mean(this_sample_size_distribution <= 2000) - mean(this_sample_size_distribution < 200))
ancestral_proportion = c(ancestral_proportion,
mean(this_sample_size_distribution > 2000))
}
figure_3A_dataframe = data.frame(
mean_list,
sd_list,
sample_size
)
# figure_3A_dataframe$sample_size = sample_size
plot_3A = ggplot(data=figure_3A_dataframe, aes(x=sample_size, y=mean_list)) +
geom_line(linewidth=1) +
geom_ribbon(aes(ymin = mean_list - sd_list, ymax = mean_list + sd_list), alpha=0.2) +
theme_bw() +
xlab('Sample size') +
ylab("Mean coalescent time (generations)") +
ggtitle("Mean coalescent time by sample size") +
geom_hline(yintercept = 1, size = 1, linetype = 'dashed')
figure_3B_dataframe = melt(data.frame(
growth_proportion,
bottleneck_proportion,
ancestral_proportion
))
figure_3B_dataframe$nu_time = dadi_time
figure_3B_dataframe$dadi_shape = dadi_nu_shape
figure_3B_dataframe$msprime_time = msprime_time
figure_3B_dataframe$msprime_shape = msprime_nu_shape
figure_3B_dataframe$sample_size = sample_size
plot_3B = ggplot(data=figure_3B_dataframe, aes(x=sample_size, y=value, color=variable, shape=dadi_shape)) +
geom_point(size=2) +
theme_bw() +
xlab('Sample size') +
ylab('Proportion') +
ggtitle('Proportion of coalescent events per epoch') +
scale_color_manual(name='Epoch',
breaks=c('growth_proportion',
'bottleneck_proportion',
'ancestral_proportion'),
values=c('growth_proportion'='#1b9e77',
'bottleneck_proportion'='#d95f02',
'ancestral_proportion'='#7570b3'),
labels=c('Recent growth', 'Bottleneck', 'Ancestral population')) +
scale_shape_manual(name='Dadi, inferred demographic event',
breaks=c('dadi_contract',
'dadi_expand'),
values=c('dadi_contract'=15,
'dadi_expand'=22),
labels=c('Dadi, contraction',
'Dadi, expansion')) +
geom_vline(xintercept=115, size=1, linetype = 'dotted', color='#0C7BDC')
plot_3C = ggplot(data=figure_3B_dataframe, aes(x=sample_size, y=value, color=variable, shape=msprime_shape)) +
geom_point(size=2) +
theme_bw() +
xlab('Sample size') +
ylab('Proportion') +
# ggtitle('Proportion of coalescent events per epoch') +
scale_color_manual(name='Epoch',
breaks=c('growth_proportion',
'bottleneck_proportion',
'ancestral_proportion'),
values=c('growth_proportion'='#1b9e77',
'bottleneck_proportion'='#d95f02',
'ancestral_proportion'='#7570b3'),
labels=c('Recent growth', 'Bottleneck', 'Ancestral population')) +
scale_shape_manual(name='MSPrime, inferred demographic event',
breaks=c('msprime_contract',
'msprime_expand'),
values=c('msprime_contract'=15,
'msprime_expand'=22),
labels=c('MSPrime, contraction',
'MSPrime, expansion')) +
guides(color='none') +
geom_vline(xintercept=95, size=1, linetype = 'dotted', color='#FFC20A')
figure_3D_dataframe = melt(data.frame(
dadi_time,
msprime_time
))
figure_3D_dataframe$sample_size=sample_size
# figure_3D_dataframe$sample_size = sample_size
plot_3D = ggplot(data=figure_3D_dataframe, aes(x=sample_size, y=value, color=variable)) +
geom_line(size=2) +
theme_bw() +
xlab('Sample size') +
ylab("Time in generations") +
ggtitle("Inferred time of instantaneous size change by sample size") +
geom_hline(yintercept = 1, size = 1, linetype = 'dashed') +
scale_y_log10() +
scale_color_manual(name='Type of time',
breaks=c('dadi_time',
'msprime_time'),
values=c(dadi_time='#0C7BDC',
msprime_time='#FFC20A'),
labels=c('Inferred dadi time',
'Inferred msprime time')
) +
geom_vline(xintercept=115, size=1, linetype = 'dotted', color='#0C7BDC') +
geom_vline(xintercept=95, size=1, linetype = 'dotted', color='#FFC20A')
plot_3A + plot_3B + plot_3C + plot_3D + plot_layout(nrow=4)
