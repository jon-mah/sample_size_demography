theme(axis.text=element_text(size=12),
axis.title=element_text(size=16))
return(fig)
}
plot_best_fit_sfs_3B = function(input_data) {
input_data = data.frame(input_data)
colnames(input_data) = c(
'Empirical Synonymous',
'Model Synonymous',
'Empirical Nonsynonymous',
'Model Nonsynonymous',
'Species',
'X.axis')
fig = ggplot(melt(input_data, id=c('Species', 'X.axis')), aes(x=X.axis, y=as.numeric(value), fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
xlab('Minor allele frequency') +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1")) +
# scale_fill_manual(values=c("#cb181d", "#fb6a4a", "blue4", "steelblue3"), name='Site-frequency-spectra') +
theme(legend.position="none") +
theme(plot.title = element_text(face = "italic", size=16)) +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=16))
return(fig)
}
plot_dfe_grid = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('shape', 'scale', 'likelihood')
unique_shape = unique(species_surface$shape)
unique_scale = unique(species_surface$scale)
Z = matrix(data=NA, nrow=length(unique_shape), ncol=length(unique_scale))
count = 1
for (i in 1:length(unique_shape)) {
for (j in 1:length(unique_scale)) {
Z[i, j] = species_surface$likelihood[count]
if (species_surface$shape[count] != unique_shape[i]) {
print('break')
} else if (species_surface$scale[count] != unique_scale[j]) {
print('break')
}
count = count + 1
}
}
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
best_params = c(species_surface$shape[1], species_surface$scale[1])
print(best_params)
MLE = max(species_surface$likelihood)
species_surface$likelihood = species_surface$likelihood - MLE
color_breakpoints = cut(species_surface$likelihood, c(-Inf, -3, -1, -0.5, 0))
likelihood_surface_title = paste('MLE @ [', str_trunc(toString(best_params[1]), 8, ellipsis=''), sep='')
likelihood_surface_title = paste(likelihood_surface_title, ', ', sep='')
likelihood_surface_title = paste(likelihood_surface_title, str_trunc(toString(best_params[2]), 8, ellipsis=''), sep='')
likelihood_surface_title = paste(likelihood_surface_title, ']', sep='')
fig = ggplot(species_surface) +
geom_contour_filled(aes(x=shape, y=scale, z=likelihood),
breaks = c(0, -0.5, -1, -3, -Inf)) +
scale_fill_brewer(palette = "YlGnBu", direction=1, name='Log Likelihood') +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
annotate('point', x=best_params[1], y=best_params[2], color='orange', size=2) +
xlab('Shape')  +
ylab('Scale') +
scale_y_log10()
#ggtitle(likelihood_surface_title)
return(fig)
}
find_dfe_mle = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('shape', 'scale', 'likelihood')
unique_shape = unique(species_surface$shape)
unique_scale = unique(species_surface$scale)
Z = matrix(data=NA, nrow=length(unique_shape), ncol=length(unique_scale))
count = 1
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
best_params = c(species_surface$shape[1], species_surface$scale[1])
print(best_params)
MLE = max(species_surface$likelihood)
print(MLE)
}
cross_species_dfe_comparison = function(input_A, input_B) {
species_surface_A = read.csv(input_A, header=TRUE)
names(species_surface_A) = c('shape', 'scale', 'likelihood')
unique_shape_A = unique(species_surface_A$shape)
unique_scale_A = unique(species_surface_A$scale)
Z_A = matrix(data=NA, nrow=length(unique_shape_A), ncol=length(unique_scale_A))
count = 1
for (i in 1:length(unique_shape_A)) {
for (j in 1:length(unique_scale_A)) {
Z_A[i, j] = species_surface_A$likelihood[count]
if (species_surface_A$shape[count] != unique_shape_A[i]) {
print('break')
} else if (species_surface_A$scale[count] != unique_scale_A[j]) {
print('break')
}
count = count + 1
}
}
temp_surface_A = species_surface_A[order(species_surface_A$likelihood, decreasing=TRUE), ]
best_params_A = c(temp_surface_A$shape[1], temp_surface_A$scale[1])
ML_A = temp_surface_A$likelihood[1]
species_surface_B = read.csv(input_B, header=TRUE)
names(species_surface_B) = c('shape', 'scale', 'likelihood')
unique_shape_B = unique(species_surface_B$shape)
unique_scale_B = unique(species_surface_B$scale)
Z_B = matrix(data=NA, nrow=length(unique_shape_B), ncol=length(unique_scale_B))
count = 1
for (i in 1:length(unique_shape_B)) {
for (j in 1:length(unique_scale_B)) {
Z_B[i, j] = species_surface_B$likelihood[count]
if (species_surface_B$shape[count] != unique_shape_B[i]) {
print('break')
} else if (species_surface_B$scale[count] != unique_scale_B[j]) {
print('break')
}
count = count + 1
}
}
temp_surface_B = species_surface_B[order(species_surface_B$likelihood, decreasing=TRUE), ]
best_params_B = c(temp_surface_B$shape[1], temp_surface_B$scale[1])
ML_B = temp_surface_B$likelihood[1]
combined_likelihood = species_surface_A$likelihood + species_surface_B$likelihood
comparison_surface = data.frame(species_surface_A$shape, species_surface_A$scale, combined_likelihood)
temp_comparison_surface = comparison_surface[order(comparison_surface$combined_likelihood, decreasing=TRUE), ]
best_params_comparison = c(temp_comparison_surface$species_surface_A.shape[1], temp_comparison_surface$species_surface_A.scale[1])
ML_comparison = temp_comparison_surface$combined_likelihood[1]
independent_sum = ML_A + ML_B
return(ML_comparison - independent_sum)
}
compare_core_accessory_sfs = function(all, core, accessory) {
x_axis = 1:length(all)
input_df = data.frame(proportional_sfs(all),
proportional_sfs(core),
proportional_sfs(accessory),
x_axis)
names(input_df) = c('All genes',
'Core genes',
'Accessory genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
compare_core_accessory_sfs_count = function(all, core, accessory) {
x_axis = 1:length(all)
input_df = data.frame(all,
core,
accessory,
x_axis)
names(input_df) = c('All genes',
'Core genes',
'Accessory genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
compare_core_accessory_sfs_syn_ns = function(core_syn, core_nonsyn, accessory_syn, accessory_nonsyn) {
x_axis = 1:length(core_syn)
input_df = data.frame(proportional_sfs(core_syn),
proportional_sfs(core_nonsyn),
proportional_sfs(accessory_syn),
proportional_sfs(accessory_nonsyn),
x_axis)
names(input_df) = c('Core genes (Syn)',
'Core genes (Nonsyn)',
'Accessory genes (Syn)',
'Accessory genes (Nonsyn)',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1"))
return(p_input_comparison)
}
compare_core_sfs = function(all, core) {
x_axis = 1:length(all)
input_df = data.frame(proportional_sfs(all),
proportional_sfs(core),
x_axis)
names(input_df) = c('All genes',
'Core genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
extract_array_length <- function(input_string) {
array_string <- str_extract(input_string, "\\[(.*?)\\]")
num_elements <- length(strsplit(array_string, "[ ,]")[[1]])
return(num_elements)
}
AIC_from_demography = function(input_file) {
## Reads input SFS from output *demography.txt
if(grepl("one_epoch", input_file)) {
k=2
} else if(grepl("two_epoch", input_file)) {
k=4
} else {
k=8
}
this_file = file(input_file)
on.exit(close(this_file))
ll_string = readLines(this_file)[2]
loglik <- as.numeric(str_extract(ll_string, "-?\\d+\\.\\d+"))
return(k - 2*loglik)
}
return_nu_high = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
highest_nu <- max(species_surface$nu)
return(highest_nu)
}
return_nu_low = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
lowest_nu <- min(species_surface$nu)
return(lowest_nu)
}
return_nu_mle = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
return(species_surface$nu[1])
}
return_time_high = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
highest_tau <- max(species_surface$tau)
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * highest_tau * theta / (4 * mu_low * allele_sum)
years = 2 * highest_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
return_time_low = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
lowest_tau <- min(species_surface$tau)
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * lowest_tau * theta / (4 * mu_low * allele_sum)
years = 2 * lowest_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
return_time_mle = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
mle_tau = species_surface$tau[i]
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * mle_tau * theta / (4 * mu_low * allele_sum)
years = 2 * mle_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
read_demography_info <- function(filepath) {
# Read the content of the file
file_content <- readLines(filepath)
# Extract the relevant lines
nu <- as.numeric(regmatches(file_content[1], regexpr("\\d+\\.\\d+", file_content[1])))
low_years <- as.numeric(regmatches(file_content[length(file_content)-3], regexpr("\\d+\\.\\d+", file_content[length(file_content)-3])))
low_ancestral_size <- as.numeric(regmatches(file_content[length(file_content)-1], regexpr("\\d+\\.\\d+", file_content[length(file_content)-1])))
# Create a vector with the extracted information
result_vector <- c(nu, low_years, low_ancestral_size)
return(result_vector)
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pchisq(274.376417233, 1, lower.tail=FALSE)
update.packages()
data = c(0.590, 0.08, 0, 0)
p_bar = mean(data)
q_bar = 1-p_bar
var_p = var(data)
var_p
var_p / p_bar / q_bar
q_bar
p_bar
var_p
var(data)
variance(data)
?var
var_p = 0.06056875
var_p / (p_bar * q_bar)
data_2 = c(0.323, 0.384, 0.229, 0.087)
p_bar_2 = mean(data_2)
q_bar_2 = 1 - p_bar_2
var_p_2 = 0.012540688
var_p_2 / p_bar_2 / q_bar_2
p_bar_2
q_bar_2
var_p_2
N <- 10000              # Population size
s <- 0.2                # Selection coefficient
h <- 0.5                # Dominance coefficient
p <- 1 / (2 * N)        # Initial frequency of light allele (1 heterozygous immigrant)
max_gen <- 500          # Max generations to simulate
# Storage for tracking allele frequency
p_vec <- numeric(max_gen)
p_vec[1] <- p
# Fitness values
w_LL <- 1 + s
w_LD <- 1 + h * s
w_DD <- 1
# Iterate over generations
for (gen in 2:max_gen) {
# Genotype frequencies (HWE assumption)
p <- p_vec[gen - 1]
q <- 1 - p
f_LL <- p^2
f_LD <- 2 * p * q
f_DD <- q^2
# Mean fitness of population
w_bar <- f_LL * w_LL + f_LD * w_LD + f_DD * w_DD
# New allele frequency after selection
p_next <- (f_LL * w_LL + 0.5 * f_LD * w_LD) / w_bar
p_vec[gen] <- p_next
# Stop early if allele frequency reaches 0.9
if (p_next >= 0.9) {
cat("Reached p = 0.9 at generation", gen, "\n")
p_vec <- p_vec[1:gen]
break
}
}
# Plot allele frequency over generations
plot(p_vec, type = "l", lwd = 2, col = "blue",
xlab = "Generation", ylab = "Frequency of light allele (p)",
main = "Allele Frequency Over Time under Selection")
abline(h = 0.9, col = "red", lty = 2)
?abline
abline(v = 131, col = 'green', lty=1)
# Plot allele frequency over generations
plot(p_vec, type = "l", lwd = 2, col = "blue",
xlab = "Generation", ylab = "Frequency of light allele (p)",
main = "Allele Frequency Over Time under Selection",
xlim = c(0, 140))
abline(h = 0.9, col = "red", lty = 2)
abline(v = 131, col = 'green', lty=1)
# figure_2.R
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source('useful_functions.R')
sample_size = seq(from=10, to=800, by=10)
dadi_nu = c()
dadi_time = c()
dadi_tajima_D = c()
msprime_nu = c()
msprime_time = c()
msprime_tajima_D = c()
for (i in sample_size) {
dadi_sfs = paste0(
"../Simulations/dadi_simulations/ThreeEpochBottleneck_", i, '.sfs')
dadi_demography = paste0(
"../Analysis/dadi_3EpB_", i, '/two_epoch_demography.txt')
dadi_nu = c(dadi_nu, nu_from_demography(dadi_demography))
dadi_time = c(dadi_time, time_from_demography(dadi_demography))
dadi_summary = paste0(
"../Simulations/dadi_simulations/ThreeEpochBottleneck_", i, '_summary.txt')
dadi_tajima_D = c(dadi_tajima_D, read_summary_statistics(dadi_summary)[3])
msprime_sfs = paste0(
"../Simulations/simple_simulations/ThreeEpochBottleneck_", i, '_concat.sfs')
msprime_demography = paste0(
"../Analysis/msprime_3EpB_", i, '/two_epoch_demography.txt')
msprime_nu = c(msprime_nu, nu_from_demography(msprime_demography))
msprime_time = c(msprime_time, time_from_demography(msprime_demography))
msprime_summary = paste0(
"../Simulations/simple_simulations/ThreeEpochBottleneck_", i, '_concat_summary.txt')
msprime_tajima_D = c(msprime_tajima_D, read_summary_statistics(msprime_summary)[3])
}
nu_dataframe = melt(data.frame(
dadi_nu,
msprime_nu
))
nu_dataframe$sample_size = sample_size
time_dataframe = melt(data.frame(
dadi_time,
msprime_time
))
time_dataframe$sample_size = sample_size
tajima_D_dataframe = melt(data.frame(
dadi_tajima_D,
msprime_tajima_D
))
tajima_D_dataframe$sample_size = sample_size
plot_A = ggplot(data=nu_dataframe, aes(x=sample_size, y=value, color=variable)) + geom_line(size=2) +
theme_bw() + guides(color=guide_legend(title="Type of SFS")) +
xlab('Sample size') +
ylab("Nu") +
ggtitle("Nu (ratio of Ancestral to Effective population size)") +
scale_colour_manual(
values = c("Blue","Yellow"),
labels = c("Dadi", "MSPrime")
) +
scale_y_log10() +
geom_hline(yintercept = 1, size = 2, linetype = 'dashed')
plot_B = ggplot(data=time_dataframe, aes(x=sample_size, y=value, color=variable)) + geom_line(size=2) +
theme_bw() + guides(color=guide_legend(title="Type of SFS")) +
xlab('Sample size') +
ylab("Generations") +
ggtitle("Time in generations for inferred instantaneous size change") +
scale_colour_manual(
values = c("Blue","Yellow"),
labels = c("Dadi", "MSPrime")
) +
scale_y_log10() +
theme(legend.position='none')
plot_C = ggplot(data=tajima_D_dataframe, aes(x=sample_size, y=value, color=variable)) + geom_line(size=2) +
theme_bw() + guides(color=guide_legend(title="Type of SFS")) +
xlab('Sample size') +
ylab("Tajima's D") +
ggtitle("Tajima's D for simulated SFS") +
scale_colour_manual(
values = c("Blue","Yellow"),
labels = c("Dadi", "MSPrime")
) +
geom_hline(yintercept = 0, size = 2, linetype = 'dashed') +
theme(legend.position='none')
plot_D = plot_likelihood_surface('../Analysis/dadi_3EpB_10/likelihood_surface.csv') +
ggtitle('Likelihood surface for dadi-simulated SFS, k=10')
plot_E = plot_likelihood_surface('../Analysis/dadi_3EpB_100/likelihood_surface.csv') +
ggtitle('Likelihood surface for dadi-simulated SFS, k=100') +
theme(legend.position='none')
plot_F = plot_likelihood_surface('../Analysis/dadi_3EpB_200/likelihood_surface.csv') +
ggtitle('Likelihood surface for dadi-simulated SFS, k=200') +
theme(legend.position='none')
design = "
AAD
BBE
CCF
"
plot_A + plot_B + plot_C + plot_D + plot_E + plot_F + plot_layout(design=design)
