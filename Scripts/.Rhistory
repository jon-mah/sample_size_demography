watterson_theta_string = readLines(this_file)[10]
# Extract the float that comes after "Watterson's Theta: "
match <- str_match(watterson_theta_string, "Watterson's Theta:\\s*([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)")
watterson_theta <- as.numeric(match[2])
pi_string = readLines(this_file)[11]
# Extract the float that comes after "Nucleotide Diversity: "
match <- str_match(pi_string, "Nucleotide Diversity:\\s*([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)")
pi <- as.numeric(match[2])
tajima_D_string = readLines(this_file)[12]
# Extract the float that comes after "Tajima's D: "
match <- str_match(tajima_D_string, "Tajima's D:\\s*([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)")
tajima_D <- as.numeric(match[2])
zeng_E_string = readLines(this_file)[13]
# Extract the float that comes after "Zeng's E: "
match <- str_match(zeng_E_string, "Zeng's E:\\s*([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)")
zeng_E <- as.numeric(match[2])
zeng_theta_L_string = readLines(this_file)[14]
# Extract the float that comes after "Zeng's Theta_L: "
match <- str_match(zeng_theta_L_string, "Zeng's Theta_L:\\s*([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)")
zeng_theta_L <- as.numeric(match[2])
return_list = c(watterson_theta, pi, tajima_D, zeng_E, zeng_theta_L)
return(return_list)
}
compare_five_full_SFS = function(
dadi_1, lynch_1,
dadi_2, lynch_2,
dadi_3, lynch_3,
dadi_4, lynch_4,
dadi_5, lynch_5
) {
length_1 = length(dadi_1)
length_2 = length(dadi_2)
length_3 = length(dadi_3)
length_4 = length(dadi_4)
length_5 = length(dadi_5)
x_axis = 1:length_5
while(length(dadi_1) < length_5) {
dadi_1 = c(dadi_1, 0)
lynch_1 = c(lynch_1, 0)
}
while(length(dadi_2) < length_5) {
dadi_2 = c(dadi_2, 0)
lynch_2 = c(lynch_2, 0)
}
while(length(dadi_3) < length_5) {
dadi_3 = c(dadi_3, 0)
lynch_3 = c(lynch_3, 0)
}
while(length(dadi_4) < length_5) {
dadi_4 = c(dadi_4, 0)
lynch_4 = c(lynch_4, 0)
}
plot_1 = compare_dadi_lynch_count_sfs(dadi_1, lynch_1) + guides(fill='none') + theme(axis.title.x = element_blank()) + ylab('')
plot_2 = compare_dadi_lynch_count_sfs(dadi_2, lynch_2) + guides(fill='none') + theme(axis.title.x = element_blank()) + ylab('')
plot_3 = compare_dadi_lynch_count_sfs(dadi_3, lynch_3) + theme(axis.title.x = element_blank()) + theme(axis.title.x = element_blank())
plot_4 = compare_dadi_lynch_count_sfs(dadi_4, lynch_4) + guides(fill='none') + theme(axis.title.x = element_blank()) + ylab('')
plot_5 = compare_dadi_lynch_count_sfs(dadi_5, lynch_5) + guides(fill='none') + ylab('')
plot_1 + plot_2 + plot_3 + plot_4 + plot_5 + plot_layout(nrow=5)
}
plot_likelihood_surface = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
nu_min = min(species_surface[[2]])
nu_max = max(species_surface[[2]])
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
MLE = max(species_surface$likelihood)
MLE_minus_3 = MLE - 3
MLE_minus_3_label = paste('<= ', str_trunc(toString(MLE_minus_3), 6, ellipsis=''), sep='')
MLE_minus_1 = MLE - 1
MLE_minus_1_label = paste(str_trunc(toString(MLE_minus_3), 6, ellipsis=''), ' <= ', str_trunc(toString(MLE_minus_1), 9, ellipsis=''), sep='')
MLE_minus_half = MLE - 0.5
MLE_minus_half_label  = paste(str_trunc(toString(MLE_minus_1), 6, ellipsis=''), ' <= ', str_trunc(toString(MLE_minus_half), 6, ellipsis=''), sep='')
MLE_label = paste(str_trunc(toString(MLE_minus_half), 6, ellipsis=''), ' <= ', str_trunc(toString(MLE), 6, ellipsis=''), sep='')
color_breakpoints = cut(species_surface$likelihood, c(-Inf, MLE_minus_3, MLE_minus_1, MLE_minus_half, MLE))
species_surface_scatter = ggplot(data=species_surface, aes(x=nu, y=tau), color=likelihood) +
geom_point(aes(colour = color_breakpoints), size = 1, shape=15) +
# geom_point(aes(colour = color_breakpoints), size = 15, shape=15) +
scale_color_manual(name='Log Likelihood',
values=c('#a6611a', '#dfc27d', '#80cdc1', '#018571'),
labels=c('(-Inf, -3]', '(-3, -1]', '(-1, -0.5', '(-0,5, 0]')) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
xlab('Nu') +
ylab('Tau')
if (nu_min < 1.0 && nu_max > 1.0) {
species_surface_scatter = species_surface_scatter +
geom_vline(xintercept=1.0, color='red', linewidth=2)
}
return(species_surface_scatter)
}
plot_likelihood_contour <- function(input) {
species_surface <- read.csv(input, header = TRUE)
names(species_surface) <- c('index', 'nu', 'tau', 'likelihood')
nu_min <- min(species_surface$nu)
nu_max <- max(species_surface$nu)
# Calculate MLE cutoffs
MLE <- max(species_surface$likelihood)
MLE_minus_3 <- MLE - 3
MLE_minus_1 <- MLE - 1
MLE_minus_half <- MLE - 0.5
# Create a factor for colour bins
species_surface$likelihood_bin <- cut(
species_surface$likelihood,
breaks = c(-Inf, MLE_minus_3, MLE_minus_1, MLE_minus_half, MLE),
include.lowest = TRUE
)
# Contour fill based on likelihood, not density
p <- ggplot(species_surface, aes(x = nu, y = tau, z = likelihood)) +
geom_contour_filled(
breaks = c(-Inf, MLE_minus_3, MLE_minus_1, MLE_minus_half, MLE)
) +
scale_fill_manual(
name = 'Log Likelihood',
values = c('#a6611a', '#dfc27d', '#80cdc1', '#018571'),
labels=c('(-Inf, -3]', '(-3, -1]', '(-1, -0.5', '(-0,5, 0]'),
drop = FALSE
) +
theme(
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank(),
axis.line = element_line(colour = "black")
) +
xlab('Nu') +
ylab('Tau')
if (nu_min < 1.0 && nu_max > 1.0) {
p <- p + geom_vline(xintercept = 1.0, color = 'red', linewidth = 2)
}
return(p)
}
plot_likelihood_surface_contour = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
nu_min <- min(species_surface$nu)
nu_max <- max(species_surface$nu)
unique_nu = unique(species_surface$nu)
unique_tau = unique(species_surface$tau)
Z = matrix(data=NA, nrow=length(unique_nu), ncol=length(unique_tau))
count = 1
for (i in 1:length(unique_nu)) {
for (j in 1:length(unique_tau)) {
Z[i, j] = species_surface$likelihood[count]
if (species_surface$nu[count] != unique_nu[i]) {
print('break')
} else if (species_surface$tau[count] != unique_tau[j]) {
print('break')
}
count = count + 1
}
}
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
best_params = c(species_surface$nu[1], species_surface$tau[1])
print(best_params)
MLE = max(species_surface$likelihood)
# print(MLE)
species_surface$likelihood = species_surface$likelihood - MLE
color_breakpoints = cut(species_surface$likelihood, c(-Inf, -3, -1, -0.5, 0))
likelihood_surface_title = paste('MLE @ [', str_trunc(toString(best_params[1]), 8, ellipsis=''), sep='')
likelihood_surface_title = paste(likelihood_surface_title, ', ', sep='')
likelihood_surface_title = paste(likelihood_surface_title, str_trunc(toString(best_params[2]), 8, ellipsis=''), sep='')
likelihood_surface_title = paste(likelihood_surface_title, ']', sep='')
xlabel_text = expression(nu == frac(N[current], N[ancestral]))
ylabel_text = expression(tau == frac(generations, 2 * N[ancestral]))
fig = ggplot(species_surface) +
geom_contour_filled(aes(x=nu, y=tau, z=likelihood),
# breaks = c(-Inf, -3, -1, -0.5, 0)) +
breaks = c(0, -0.5, -1, -3, -Inf)) +
scale_fill_brewer(palette = "YlGnBu", direction=1, name='Log Likelihood') +
# geom_vline(xintercept=1.0, color='red', linewidth=1, linetype='dashed') +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
annotate('point', x=best_params[1], y=best_params[2], color='orange', size=2) +
xlab(xlabel_text)  +
ylab(ylabel_text)
# ggtitle(likelihood_surface_title)
if (nu_min < 1.0 && nu_max > 1.0) {
fig <- fig + geom_vline(xintercept = 1.0, color = 'red', linewidth = 1, linetype='dashed')
}
return(fig)
}
find_CI_bounds <- function(input) {
# Read CSV and drop index column
df <- read.csv(input, header = TRUE)
df <- df[, c("X", "Y", "Z")]  # keep only relevant columns
# Find MLE
MLE <- max(df$Z, na.rm = TRUE)
# Filter for points within 3 units of MLE
df_MLE <- df[df$Z == MLE, ]
df_near_MLE <- subset(df, Z >= (MLE - 3))
# Find min/max for nu and tau
CI_bounds <- list(
MLE = MLE,
nu_MLE = unique(df_MLE$X)[1],
tau_MLE= unique(df_MLE$Y)[1],
nu_min = min(df_near_MLE$X, na.rm = TRUE),
nu_max = max(df_near_MLE$X, na.rm = TRUE),
tau_min = min(df_near_MLE$Y, na.rm = TRUE),
tau_max = max(df_near_MLE$Y, na.rm = TRUE)
)
return(CI_bounds)
}
# figure_2.R
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source('useful_functions.R')
sample_size = seq(from=10, to=800, by=10)
dadi_nu = c()
dadi_time = c()
dadi_tau = c()
dadi_tajima_D = c()
dadi_lambda_32 = c()
dadi_lambda_21 = c()
dadi_one_LL = c()
dadi_two_LL = c()
dadi_three_LL = c()
dadi_nu_min = c()
dadi_nu_max = c()
dadi_tau_min = c()
dadi_tau_max = c()
dadi_nu_b = c()
dadi_nu_f = c()
msprime_nu = c()
msprime_time = c()
msprime_tau = c()
msprime_tajima_D = c()
msprime_lambda_32 = c()
msprime_lambda_21 = c()
msprime_one_LL = c()
msprime_two_LL = c()
msprime_three_LL = c()
# msprime_lambda = rep(0, 80)
msprime_nu_min = c()
msprime_nu_max = c()
msprime_tau_min = c()
msprime_tau_max = c()
msprime_nu_b = c()
msprime_nu_f = c()
for (i in sample_size) {
dadi_sfs = paste0(
"../Simulations/dadi_simulations/ThreeEpochBottleneck_", i, '.sfs')
dadi_demography = paste0(
"../Analysis/dadi_3EpB_", i, '/two_epoch_demography.txt')
dadi_demography_1 = paste0(
"../Analysis/dadi_3EpB_", i, '/one_epoch_demography.txt')
dadi_demography_3 = paste0(
"../Analysis/dadi_3EpB_", i, '/three_epoch_demography.txt')
dadi_likelihood = paste0(
"../Analysis/dadi_3EpB_", i, '/likelihood_surface.csv')
# dadi_nu = c(dadi_nu, nu_from_demography(dadi_demography))
dadi_time = c(dadi_time, time_from_demography(dadi_demography))
dadi_summary = paste0(
"../Simulations/dadi_simulations/ThreeEpochBottleneck_", i, '_summary.txt')
dadi_tajima_D = c(dadi_tajima_D, read_summary_statistics(dadi_summary)[3])
this_dadi_one_LL = LL_from_demography(dadi_demography_1)
this_dadi_two_LL = LL_from_demography(dadi_demography)
this_dadi_three_LL = LL_from_demography(dadi_demography_3)
dadi_one_LL = c(dadi_one_LL, this_dadi_one_LL)
dadi_two_LL = c(dadi_two_LL, this_dadi_two_LL)
dadi_three_LL = c(dadi_three_LL, this_dadi_three_LL)
dadi_LL_diff_32 = this_dadi_three_LL - this_dadi_two_LL
dadi_lambda_32 = c(dadi_lambda_32, 2 * dadi_LL_diff_32)
dadi_LL_diff_21 = this_dadi_two_LL - this_dadi_one_LL
dadi_lambda_21 = c(dadi_lambda_21, 2 * dadi_LL_diff_21)
dadi_nu = c(dadi_nu, find_CI_bounds(dadi_likelihood)$nu_MLE)
dadi_nu_min = c(dadi_nu_min, find_CI_bounds(dadi_likelihood)$nu_min)
dadi_nu_max = c(dadi_nu_max, find_CI_bounds(dadi_likelihood)$nu_max)
dadi_tau = c(dadi_tau, find_CI_bounds(dadi_likelihood)$tau_MLE)
dadi_tau_min = c(dadi_tau_min, find_CI_bounds(dadi_likelihood)$tau_min)
dadi_tau_max = c(dadi_tau_max, find_CI_bounds(dadi_likelihood)$tau_max)
dadi_nu_b = c(dadi_nu_b, nuB_from_demography(dadi_demography_3))
dadi_nu_f = c(dadi_nu_f, nuF_from_demography(dadi_demography_3))
msprime_sfs = paste0(
"../Simulations/simple_simulations/ThreeEpochBottleneck_", i, '_concat.sfs')
msprime_demography = paste0(
"../Analysis/msprime_3EpB_", i, '/two_epoch_demography.txt')
msprime_demography_1 = paste0(
"../Analysis/msprime_3EpB_", i, '/one_epoch_demography.txt')
msprime_demography_3 = paste0(
"../Analysis/msprime_3EpB_", i, '/three_epoch_demography.txt')
# msprime_nu = c(msprime_nu, nu_from_demography(msprime_demography))
msprime_time = c(msprime_time, time_from_demography(msprime_demography))
msprime_summary = paste0(
"../Simulations/simple_simulations/ThreeEpochBottleneck_", i, '_concat_summary.txt')
msprime_likelihood = paste0(
"../Analysis/msprime_3EpB_", i, '/likelihood_surface.csv')
msprime_nu = c(msprime_nu, find_CI_bounds(msprime_likelihood)$nu_MLE)
msprime_nu_min = c(msprime_nu_min, find_CI_bounds(msprime_likelihood)$nu_min)
msprime_nu_max = c(msprime_nu_max, find_CI_bounds(msprime_likelihood)$nu_max)
msprime_tau = c(msprime_tau, find_CI_bounds(msprime_likelihood)$tau_MLE)
msprime_tau_min = c(msprime_tau_min, find_CI_bounds(msprime_likelihood)$tau_min)
msprime_tau_max = c(msprime_tau_max, find_CI_bounds(msprime_likelihood)$tau_max)
msprime_tajima_D = c(msprime_tajima_D, read_summary_statistics(msprime_summary)[3])
this_msprime_one_LL = LL_from_demography(msprime_demography_1)
this_msprime_two_LL = LL_from_demography(msprime_demography)
this_msprime_three_LL = LL_from_demography(msprime_demography_3)
msprime_one_LL = c(msprime_one_LL, this_msprime_one_LL)
msprime_two_LL = c(msprime_two_LL, this_msprime_two_LL)
msprime_three_LL = c(msprime_three_LL, this_msprime_three_LL)
msprime_LL_diff_32 = this_msprime_three_LL - this_msprime_two_LL
msprime_lambda_32 = c(msprime_lambda_32, 2 * msprime_LL_diff_32)
msprime_LL_diff_21 = this_msprime_two_LL - this_msprime_one_LL
msprime_lambda_21 = c(msprime_lambda_21, 2 * msprime_LL_diff_21)
msprime_nu_b = c(msprime_nu_b, nuB_from_demography(msprime_demography_3))
msprime_nu_f = c(msprime_nu_f, nuF_from_demography(msprime_demography_3))
}
nu_label_text = expression(nu == frac(N[current], N[ancestral]))
tau_label_text = expression(tau == frac(generations, 2 * N[ancestral]))
twoLambda_text = expression(2*Lambda)
nu_dataframe = melt(data.frame(
# dadi_nu,
msprime_nu
))
nu_dataframe$sample_size = sample_size
# nu_dataframe$dadi_min = dadi_nu_min
# nu_dataframe$dadi_max = dadi_nu_max
nu_dataframe$msprime_min = msprime_nu_min
nu_dataframe$msprime_max = msprime_nu_max
# Min nu for contractions
min(nu_dataframe[1:9, ]$value)
# Max nu for expansions
max(nu_dataframe[1:9, ]$value)
nu_dataframe_CI_bounds = melt(data.frame(
dadi_nu_min,
dadi_nu_max
))
nu_dataframe_CI_bounds$sample_size = sample_size
tau_dataframe = melt(data.frame(
# dadi_tau,
msprime_tau
))
tau_dataframe$sample_size = sample_size
# tau_dataframe$dadi_min = dadi_tau_min
# tau_dataframe$dadi_max = dadi_tau_max
tau_dataframe$msprime_min = msprime_tau_min
tau_dataframe$msprime_max = msprime_tau_max
# Min tau
min(tau_dataframe[1:9, ]$value)
# Max tau
max(tau_dataframe[1:9, ]$value)
tajima_D_dataframe = melt(data.frame(
# dadi_tajima_D,
msprime_tajima_D
))
tajima_D_dataframe$sample_size = sample_size
lambda_dataframe = melt(data.frame(
dadi_lambda_32,
dadi_lambda_21,
msprime_lambda_32,
msprime_lambda_21
))
lambda_dataframe$sample_size = sample_size
lambda_dataframe_msprime = melt(data.frame(
msprime_lambda_32,
msprime_lambda_21
))
lambda_dataframe_msprime$sample_size = sample_size
dadi_nuF_nuB = dadi_nu_f / dadi_nu_b
msprime_nuF_nuB = msprime_nu_f / msprime_nu_b
epoch_ratio_dataframe = melt(data.frame(
dadi_nu_b,
dadi_nuF_nuB,
msprime_nu_b,
msprime_nuF_nuB
))
epoch_ratio_dataframe$sample_size = sample_size
epoch_ratio_dataframe_dadi = melt(data.frame(
dadi_nu_b,
dadi_nuF_nuB
))
epoch_ratio_dataframe_dadi$sample_size = sample_size
epoch_ratio_dataframe_msprime = melt(data.frame(
msprime_nu_b,
msprime_nuF_nuB
))
epoch_ratio_dataframe_msprime$sample_size = sample_size
plot_A = ggplot(data=nu_dataframe, aes(x=sample_size, y=value, color=variable)) + geom_line(size=1) +
theme_bw() + guides(color=guide_legend(title="Type of SFS")) +
# geom_ribbon(aes(ymin = dadi_min, ymax = dadi_max), fill = "#0C7BDC", color="#0C7BDC", alpha = 0.2) +
geom_ribbon(aes(ymin = msprime_min, ymax = msprime_max), fill = "#0C7BDC", color="#0C7BDC", alpha = 0.2) +
xlab('Sample size') +
ylab(nu_label_text) +
ggtitle("Ratio of Effective to Ancestral population size") +
scale_colour_manual(
values = c("#0C7BDC"),
labels = c("MSPrime")
) +
scale_y_log10() +
geom_hline(yintercept = 1, size = 2, linetype = 'dashed')
plot_B = ggplot(data=tau_dataframe, aes(x=sample_size, y=value, color=variable)) + geom_line(size=1) +
theme_bw() + guides(color=guide_legend(title="Type of SFS")) +
# geom_ribbon(aes(ymin = dadi_min, ymax = dadi_max), fill = "#0C7BDC", color="#0C7BDC", alpha = 0.2) +
geom_ribbon(aes(ymin = msprime_min, ymax = msprime_max), fill = "#0C7BDC", color="#0C7BDC", alpha = 0.2) +
xlab('Sample size') +
ylab(tau_label_text) +
ggtitle('Timing of inferred instantaneous size change') +
scale_y_log10() +
scale_colour_manual(
values = c("#0C7BDC", "#FFC20A"),
labels = c("MSPrime", "Dadi")
) +
theme(legend.position='none')
plot_C = ggplot(data=tajima_D_dataframe, aes(x=sample_size, y=value, color=variable)) + geom_line(size=1) +
theme_bw() + guides(color=guide_legend(title="Type of SFS")) +
xlab('Sample size') +
ylab("Tajima's D") +
ggtitle("Tajima's D for simulated SFS") +
scale_colour_manual(
values = c("#0C7BDC"),
labels = c("MSPrime")
) +
geom_hline(yintercept = 0, size = 2, linetype = 'dashed') +
theme(legend.position='none')
plot_D = ggplot(data=lambda_dataframe, aes(x=sample_size, y=value, color=variable)) + geom_line(size=2) +
theme_bw() + guides(color=guide_legend(title="Demographic model comparison")) +
xlab('Sample size') +
ylab(twoLambda_text) +
ggtitle("Demographic model fit criterion, three-epoch vs. two-epoch") +
scale_colour_manual(
values = c("#0C7BDC", "#999ED9", "#FFC20A", "#CA5A08"),
labels = c("Dadi, three-epoch vs. two-epoch", "Dadi, two-epoch vs. one-epoch",
"MSPrime, three-epoch vs. two-epoch", "MSPrime, two-epoch vs. one-epoch")
) +
geom_hline(yintercept = 14.75552, size = 1, linetype = 'dashed', color='red')
plot_D_2 = ggplot(data=lambda_dataframe_msprime, aes(x=sample_size, y=value, color=variable)) + geom_line(size=2) +
theme_bw() + guides(color=guide_legend(title="Demographic model comparison")) +
xlab('Sample size') +
ylab(twoLambda_text) +
ggtitle("Demographic model fit criterion, three-epoch vs. two-epoch") +
scale_colour_manual(
values = c("#f768a1", "#ae017e"),
labels = c("MSPrime, three-epoch vs. two-epoch", "MSPrime, two-epoch vs. one-epoch")
) +
scale_y_log10() +
geom_hline(yintercept = 14.75552, size = 1, linetype = 'dashed', color='red')
# 2Lambda is approximately chi-squared distributed.
# 80 comparisons for 10-800:10, so critical value is 14.76 with Bonferroni correction
qchisq(1 - 0.05/80, df=2)
plot_E = ggplot(data=epoch_ratio_dataframe, aes(x=sample_size, y=value, color=variable)) + geom_line(size=2) +
theme_bw() + guides(color=guide_legend(title="Epoch Comparison")) +
xlab('Sample size') +
ylab("Ratio of effective population size") +
ggtitle("Effective population size between epochs") +
scale_colour_manual(
values = c("#0C7BDC", "#999ED9", "#FFC20A", "#CA5A08"),
labels = c("Dadi, Bottleneck vs. Ancestral", "Dadi, Current vs. Bottleneck",
"MSPrime, Bottleneck vs. Ancestral", "MSPrime, Current vs. Bottleneck")
) +
geom_hline(yintercept = 1, size = 1, linetype = 'dashed', color='red')
plot_E_1 = ggplot(data=epoch_ratio_dataframe_dadi, aes(x=sample_size, y=value, color=variable)) + geom_line(size=2) +
theme_bw() + guides(color=guide_legend(title="Epoch Comparison")) +
xlab('Sample size') +
ylab("Ratio of effective population size") +
ggtitle("Effective population size between epochs") +
scale_colour_manual(
values = c("#0C7BDC", "#999ED9"),
labels = c("Dadi, Bottleneck vs. Ancestral", "Dadi, Current vs. Bottleneck")
) +
geom_hline(yintercept = 1, size = 1, linetype = 'dashed', color='red')
plot_E_2 = ggplot(data=epoch_ratio_dataframe_msprime, aes(x=sample_size, y=value, color=variable)) + geom_line(size=2) +
theme_bw() + guides(color=guide_legend(title="Epoch Comparison")) +
xlab('Sample size') +
ylab("Ratio of effective population size") +
ggtitle("Effective population size between epochs") +
scale_colour_manual(
values = c("#41ab5d", "#006837"),
labels = c("MSPrime, Bottleneck vs. Ancestral", "MSPrime, Current vs. Bottleneck")
) +
scale_y_log10() +
geom_hline(yintercept = 1, size = 1, linetype = 'dashed', color='red')
# plot_E = plot_likelihood_surface_contour('../Analysis/dadi_3EpB_50/likelihood_surface.csv') +
#   ggtitle('Likelihood surface for dadi-simulated SFS, k=50') +
#   theme(axis.title.x=element_blank())
# find_CI_bounds('../Analysis/dadi_3EpB_50/likelihood_surface.csv')$nu_min
# plot_F = plot_likelihood_surface_contour('../Analysis/dadi_3EpB_100/likelihood_surface.csv') +
#   ggtitle('Likelihood surface for dadi-simulated SFS, k=100') +
#   theme(axis.title.x=element_blank(), axis.title.y=element_blank())
# plot_G = plot_likelihood_surface_contour('../Analysis/dadi_3EpB_200/likelihood_surface.csv') +
#   ggtitle('Likelihood surface for dadi-simulated SFS, k=200') +
#   theme(axis.title.x=element_blank(), axis.title.y=element_blank())
#
# plot_H = plot_likelihood_surface_contour('../Analysis/dadi_3EpB_300/likelihood_surface.csv') +
#   ggtitle('Likelihood surface for dadi-simulated SFS, k=300') +
#   theme(legend.position='none')
#
# loglik_dataframe = melt(data.frame(
#   dadi_two_LL,
#   dadi_three_LL
# ))
# loglik_dataframe$sample_size = sample_size
# ggplot(data=loglik_dataframe, aes(x=sample_size, y=value, color=variable)) + geom_line(size=2) +
#   theme_bw() + guides(color=guide_legend(title="Type of SFS")) +
#   xlab('Sample size') +
#   ylab("Log likelihood") +
#   ggtitle("Log likelihood for simulated SFS") +
#   scale_colour_manual(
#     values = c("#0C7BDC","#FFC20A"),
#     labels = c("Two-epoch", "Three-epoch")
#   ) +
#   geom_hline(yintercept = 0, size = 2, linetype = 'dashed')
#
design = "
CCDD
AAEE
BBEE
"
## Figure 2
# 1200 x 800
plot_A +
plot_B +
plot_C +
plot_D_2 +
plot_E_2 +
plot_layout(design=design)
